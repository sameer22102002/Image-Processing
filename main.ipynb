{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8gq93kra9E0V"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gaze_tracking'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Sameer\\OneDrive\\Desktop\\Everything\\python\\curr\\main.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sameer/OneDrive/Desktop/Everything/python/curr/main.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mface_recognition\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sameer/OneDrive/Desktop/Everything/python/curr/main.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcvzone\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sameer/OneDrive/Desktop/Everything/python/curr/main.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgaze_tracking\u001b[39;00m \u001b[39mimport\u001b[39;00m GazeTracking\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sameer/OneDrive/Desktop/Everything/python/curr/main.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m background \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mresources/background.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Sameer/OneDrive/Desktop/Everything/python/curr/main.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gaze_tracking'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import cvzone\n",
        "from gaze_tracking import GazeTracking\n",
        "\n",
        "background = cv2.imread('resources/background.png')\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, 640)\n",
        "cap.set(4, 480)\n",
        "\n",
        "# Importing the mode images into a list\n",
        "folderModePath = 'C:/Users/Sameer/OneDrive/Desktop/Everything/python/curr/Resources/modes/'\n",
        "modesPathList = os.listdir(folderModePath)\n",
        "imgModeList = []\n",
        "\n",
        "for path in modesPathList:\n",
        "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
        "\n",
        "# load the encoded file\n",
        "print(\"Loading Encode File ...\")\n",
        "file = open('EncodeFile.p', 'rb')\n",
        "encodeListKnownWithIds = pickle.load(file)\n",
        "file.close()\n",
        "encodeListKnown, studentIds = encodeListKnownWithIds\n",
        "print(\"Encode File Loaded!\")\n",
        "\n",
        "# Initialize gaze tracking\n",
        "gaze = GazeTracking()\n",
        "\n",
        "modeType = 0\n",
        "counter = 0\n",
        "id = -1\n",
        "imgStudent = []\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    success, img = cap.read()\n",
        "\n",
        "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
        "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faceCurFrame = face_recognition.face_locations(imgS)\n",
        "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
        "\n",
        "    background[162:162 + 480, 55:55 + 640] = img\n",
        "    background[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
        "\n",
        "    flag = 0\n",
        "    if faceCurFrame:\n",
        "        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
        "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "\n",
        "            matchIndex = np.argmin(faceDis)\n",
        "            if matches[matchIndex]:\n",
        "                y1, x2, y2, x1 = faceLoc\n",
        "                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
        "                bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
        "                background = cvzone.cornerRect(background, bbox, rt=0)\n",
        "                id = studentIds[matchIndex]\n",
        "                print('Face matched')\n",
        "                flag = 1\n",
        "            else:\n",
        "                print(\"Match not found!\")\n",
        "\n",
        "    # Perform gaze tracking\n",
        "    gaze.refresh(imgS)\n",
        "    left_gaze = gaze.is_left()\n",
        "    right_gaze = gaze.is_right()\n",
        "\n",
        "    if left_gaze:\n",
        "        print(\"Gaze: Left\")\n",
        "    elif right_gaze:\n",
        "        print(\"Gaze: Right\")\n",
        "    else:\n",
        "        print(\"Gaze: Center\")\n",
        "\n",
        "    if flag:\n",
        "        break\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow(\"Attendance Sys\", background)\n",
        "\n",
        "    # Press 'q' to exit the loop and close the camera\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the camera and close the OpenCV window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
